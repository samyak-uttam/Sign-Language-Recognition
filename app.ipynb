{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from PIL import ImageTk, Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('Constants.json')\n",
    "data = json.load(f)\n",
    "\n",
    "labels = data['labels']\n",
    "\n",
    "# number of classes\n",
    "NUM_CLASSES = data['NUM_CLASSES']\n",
    "\n",
    "# size of the images to be generated\n",
    "IMG_SIZE = data['TRAIN_IMG_SIZE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the weights for the model\n",
    "model=load_model('sign_lang.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 200, 200, 32)      320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 100, 100, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 12, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              18875392  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 37)                37925     \n",
      "=================================================================\n",
      "Total params: 20,481,317\n",
      "Trainable params: 20,481,317\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(frame):\n",
    "    \n",
    "    # convert to grayscale\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # defining the ROI\n",
    "    x1 = int(0.5 * frame.shape[1])\n",
    "    y1 = 5\n",
    "    x2 = frame.shape[1] - 5\n",
    "    y2 = int(0.7 * frame.shape[0])\n",
    "    cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 1)\n",
    "\n",
    "    # extracting the ROI\n",
    "    roi = image[y1:y2, x1:x2]\n",
    "\n",
    "    # blur the mask to help remove noise, then apply the\n",
    "    # mask to the frame\n",
    "    blur = cv2.GaussianBlur(roi, (5, 5), 5)\n",
    "\n",
    "    # apply opening transformation to the mask\n",
    "    # using an elliptical kernel\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    image = cv2.morphologyEx(blur, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # use thresholding technique for segmenting the hand from the frame\n",
    "    thr = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    ret, hand_img = cv2.threshold(thr, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    return hand_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GUI:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.current_word=''\n",
    "        self.sentence=''\n",
    "        self.charecter=''\n",
    "        \n",
    "        self.cap=cv2.VideoCapture(0)\n",
    "        self.root=Tk()\n",
    "        \n",
    "        self.video_label=Label(self.root)\n",
    "        self.video_label.grid(row=100,column=500,rowspan=200,columnspan=900)\n",
    "\n",
    "        # Prediction Description Label\n",
    "        self.predicted_desc=Label(self.root)\n",
    "        self.predicted_desc.grid(row=600,column=10)\n",
    "        self.predicted_desc.config(text=\"Character :\",font=(\"Courier\",40,\"bold\"))\n",
    "\n",
    "        self.char = StringVar()\n",
    "\n",
    "        # Prediction Label\n",
    "        self.predicted=Label(self.root,textvariable=self.char)\n",
    "        self.predicted.grid(row=600,column=60)\n",
    "        self.predicted.config(textvariable=self.char,font=(\"Courier\",40,\"bold\"))\n",
    "\n",
    "        # Word Description Label\n",
    "        self.word_desc=Label(self.root,text='Word:')\n",
    "        self.word_desc.grid(row=1000,column=10)\n",
    "\n",
    "        self.word = StringVar()\n",
    "\n",
    "        # Prediction Label\n",
    "        self.word_formed=Label(self.root,textvariable=self.word)\n",
    "        self.word_formed.grid(row=1000,column=60)\n",
    "        \n",
    "        self.video_stream()\n",
    "\n",
    "    def updateDepositLabel(self,*args):\n",
    "        self.char.set(args[0])\n",
    "        self.word.set(args[1])\n",
    "        \n",
    "    # function for video streaming\n",
    "    def video_stream(self):\n",
    "        \n",
    "        ret,frame = self.cap.read()\n",
    "        frame = cv2.flip(frame, 30)\n",
    "\n",
    "        hand_img=preprocess(frame)\n",
    "        self.prediction=self.predict(hand_img)\n",
    "        if(len(self.current_word)!=0 and self.prediction=='blank'):\n",
    "            self.current_word=''\n",
    "        elif(self.prediction!='blank'):\n",
    "            self.current_word+=self.prediction\n",
    "\n",
    "        self.updateDepositLabel(self.prediction,self.current_word)\n",
    "        cv2Img=cv2.cvtColor(frame,cv2.COLOR_BGR2RGBA)\n",
    "        img = Image.fromarray(cv2Img)\n",
    "        imgtk = ImageTk.PhotoImage(image=img)\n",
    "        self.video_label.imgtk = imgtk\n",
    "        self.video_label.configure(image=imgtk)\n",
    "        self.video_label.after(1, self.video_stream)\n",
    "        \n",
    "    def predict(self,hand_img):\n",
    "        resized_hand_img=cv2.resize(hand_img, (IMG_SIZE, IMG_SIZE))\n",
    "        x_test = np.array(resized_hand_img)\n",
    "        x_test = x_test.reshape(1, IMG_SIZE, IMG_SIZE, 1)\n",
    "        y_pred = np.argmax(model.predict(x_test))\n",
    "\n",
    "        return labels[str(y_pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gui=GUI()\n",
    "gui.root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gui.cap.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
